{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive linear neurons\n",
    "\n",
    "Adaline was published by Bernard Widrow and his doctoral student Tedd Hoff, only a few years after Frank Rosenblatt's perceptron algorithm, and can be considered as an improvement on the latter. The Adaline algorithm is particularly interesting because it illustrates the key concepts of defining and minimizing continuous cost functions. This lays the groundwork for understanding more advanced machine learning algorithms for classification, such as logistic regression, support vector machines, and regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference between the Adaline rule (also known as the Widrow-Hoff rule) and Rosenblatt's perceptron is that the weights are updated based on a linear activation function rather than a unit step function like in the perceptron. In Adaline, this linear activation function is simply the identity function $\\phi(z)$ of the net input, so that:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\phi \\left( w^Tx \\right) = w^t x\n",
    "\\end{equation*}\n",
    "\n",
    "While the linear activation function is used for learning the weights, we still use a threshold function to make the final prediction. The main differences between the perceptron and Adaline algorithm are highlighted in the following figure:\n",
    "\n",
    "<img src=\"images/perceptron_adaline.jpeg\" alt=\"Perceptron and Adaline\" title=\"Perceptron and Adaline\" width=\"350\" height=\"250\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minimizing cost functions\n",
    "\n",
    "One of the key ingredients of supervised machine learning algorithms is a defined **objective function** that is to be optimized during the learning process. In the case of Adaline, we can define the cost function $j$ to learn the weights as the **Sum of Squared Errors (SSE)** between the calculated outcome and the true class label :\n",
    "\n",
    "\\begin{equation*}\n",
    "j(w) = \\frac{1}{2} \\sum_i \\left( y^{(i)} - \\phi \\left( z^{(i)}\\right) \\right)^2\n",
    "\\end{equation*}\n",
    "\n",
    "The main advantage of this continuous linear activation function, in contrast to the unit step function, is that the cost function becomes differentiable.  Another nice property of this cost function is that it is convex, so we can use the **gradient descent** algorithm to find the weights that minimize our cost function to classify the samples in the Iris dataset. As illustrated in the following figure, we can describe the main idea behind gradient descent as climbing down a hill until a local or global cost minimum is reached.\n",
    "\n",
    "<img src=\"images/gradient_descent.jpeg\" alt=\"Gradient descent\" title=\"Gradient descent\" width=\"350\" height=\"250\" >\n",
    "\n",
    "Using gradient descent, we can now update the weights by taking a step in the opposite direction of the gradient $\\nabla j(w)$ of our cost function $j(w)$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "w := w + \\Delta w\n",
    "\\end{equation*}\n",
    "\n",
    "Where the weight change $\\Delta w$ is defined as the negative gradient multiplied by the learning rate $\\eta$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Delta w = -\\eta \\nabla J (w)\n",
    "\\end{equation*}\n",
    "\n",
    "To compute the gradient of the cost function, we need to compute the partial derivative of the cost function with respect to each weight $w_j$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial J}{\\partial w_j} = -\\sum_i \\left(y^{(i)} - \\phi \\left(z^{(i)} \\right ) \\right )x_j^{(i)}\n",
    "\\end{equation*}\n",
    "\n",
    "So that we can write the update of weight $w_j$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Delta w_j = -\\eta \\frac{\\partial J}{\\partial w_j} = \\eta \\sum_i \\left(y^{(i)} - \\phi \\left(z^{(i)} \\right ) \\right ) x_j^{(i)}\n",
    "\\end{equation*}\n",
    "\n",
    "Since we update all weights simultaneously, our Adaline learning rule becomes:\n",
    "\n",
    "\\begin{equation*}\n",
    "w := w + \\Delta w\n",
    "\\end{equation*}\n",
    "\n",
    "Although the Adaline learning rule looks identical to the perceptron rule, we should note that the $\\phi (z^{(i)}$ is a real number and not an integer class label. Furthermore, the weight update is calculated based on all samples in the training set (instead of updating the weights incrementally after each sample), which is why this approach is also referred to as **batch gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class AdalineGD(object):\n",
    "    \"\"\"ADAptative Linear Neuron classifier. \"\"\"\n",
    "\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        \"\"\"\n",
    "        Perceptron classifier.\n",
    "\n",
    "        :param eta: (float) Learning rate (between 0.0 and 1.0)\n",
    "        :param n_iter: (int) Passes over the training dataset\n",
    "        :param random_state: (int) Random number generator seed for random weight initialization.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "\n",
    "        Fit training data.\n",
    "\n",
    "        :param x: {array-like, shape=[n_samples, n_features]} Training vectors, where n_samples is the number of\n",
    "        samples and n_features is the number of features.\n",
    "        :param y: {array-like, shape=n_samples} Target values.\n",
    "        :rtype: AdalineGD\n",
    "        :return: self\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def net_input(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        Calculate net input\n",
    "\n",
    "        :param x: {array-like, shape=[n_samples, n_features]} Training vectors, where n_samples is the number of\n",
    "        samples and n_features is the number of features.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Return class label after unit step\n",
    "\n",
    "        :param x: {array-like, shape=[n_samples, n_features]} Training vectors, where n_samples is the number of\n",
    "        samples and n_features is the number of features.\n",
    "        :return:\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def activation(self, x):\n",
    "        \"\"\"\n",
    "        Compute linear activation\n",
    "        :param x: input\n",
    "        :return: linear activation\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, it often requires some experimentation to find a good learning rate $\\eta$ for optimal convergence. So, let's choose two different learning rates, $\\eta = 0.1$ and $\\eta = 0.0001$, to start with and plot the cost functions versus the number of epochs to see how well the Adaline implementation learns from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga los datos de Iris, genera el dataset y entrena un perceptrón utilizando eta=0.1 y otro con eta=0.0001\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the resulting cost-function plots, we encountered two different types of problem. The left chart shows what could happen if we choose a learning rate that is too large. Instead of minimizing the cost function, the error becomes larger in every epoch, because we **overshoot** the global minimum. On the other hand, we can see that the cost decreases on the right plot, but the chosen learning rate $\\eta$ is so small that the algorithm would require a very large number of epochs to converge to the global cost minimum.\n",
    "\n",
    "The following figure illustrates what might happen if we change the value of a particular weight parameter to minimize the cost function.\n",
    "\n",
    "<img src=\"images/good_bad_learning_rate.jpeg\" alt=\"Good and bad learning rate\" title=\"Good and bad learning rate\" width=\"550\" height=\"350\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra la los espacios de clasificación del perceptrón\n",
    "from plot_decision import plot_decision_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature scaling\n",
    "\n",
    "Many machine learning algorithms that we will encounter throughout this book require some sort of feature scaling for optimal performance. Gradient descent is one of the many algorithms that benefit from feature scaling. we will use a feature scaling method called **standardization**. Standardization shifts the mean of each feature so that it is centered at zero and each feature has a standard deviation of 1. For instance, to standardize the *jth* feature, we can simply subtract the sample mean $\\mu_j$ from every training sample and divide it by its standard deviation $\\sigma_j$:\n",
    "\n",
    "\\begin{equation*}\n",
    "x'_j = \\frac{x_j - \\mu_j}{\\sigma_j}\n",
    "\\end{equation*}\n",
    "\n",
    "One of the reasons why standardization helps with gradient descent learning is that the optimizer has to go through fewer steps to find a good or optimal solution (the global cost minimum), as illustrated in the following figure:\n",
    "\n",
    "<img src=\"images/gradient_standarization.jpg\" alt=\"Good and bad learning rate\" title=\"Good and bad learning rate\" width=\"550\" height=\"350\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrena una neurona AdalineGD con 15 epocas y eta=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica el error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stochastic gradient descent\n",
    "\n",
    "we learned how to minimize a cost function by taking a step in the opposite direction of a cost gradient that is calculated from the whole training set; this is why this approach is sometimes also referred to as **batch gradient descent**. Running batch gradient descent can be computationally quite costly in scenarios with a large data set since we need to reevaluate the whole training dataset each time we take one step towards the global minimum. A popular alternative to the batch gradient descent algorithm is **stochastic gradient descent**, sometimes also called iterative or **online gradient descent**.\n",
    "\n",
    "Instead of updating the weights based on the sum of the accumulated errors over all samples $x^{(i)}$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Delta w = \\eta \\sum_i \\left( y^{(i) - \\phi\\left( x^{(i)} \\right)} \\right) x^{(i)}\n",
    "\\end{equation*}\n",
    "\n",
    "We update the weights incrementally for each training sample:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\eta \\left( y^{(i)} - \\phi \\left( z^{(i)}\\right) \\right) x^{(i)}\n",
    "\\end{equation*}\n",
    "\n",
    "To obtain satisfying results via stochastic gradient descent, it is important to present it training data in a random order; also, we want to shuffle the training set for every epoch to prevent cycles.\n",
    "\n",
    "\n",
    "Another advantage of stochastic gradient descent is that we can use it for online learning. In online learning, our model is trained on the fly as new training data arrives. This is especially useful if we are accumulating large amounts of data, for example, customer data in web applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementa la clase AdalineSGD\n",
    "class AdalineSGD(AdalineGD):\n",
    "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "    def _shuffle(self, x, y):\n",
    "        \"\"\"\n",
    "        Shuffle trainig data\n",
    "        \"\"\"\n",
    "\n",
    "    def _initialize_wirghts(self, m):\n",
    "        \"\"\"\n",
    "        Initialize weights to small random numbers\n",
    "        :param m:\n",
    "        \"\"\"\n",
    "\n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"\n",
    "        Apply Adaline learning rule to update the weights\n",
    "        \"\"\"\n",
    "\n",
    "    def partial_fit(self, x, y):\n",
    "        \"\"\"Fit training data without reinitializing the weights\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrena una neurona mediante la clase AdalineSGD con 15 epocas, 0.01 de eta y random_state=1\n",
    "# grafica los espacios de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica el error de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
