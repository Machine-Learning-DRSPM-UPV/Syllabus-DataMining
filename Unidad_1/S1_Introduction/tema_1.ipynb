{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine learning\n",
    "\n",
    "When most people hear \"Machine learning\" they picture a robot: a dependable butler or a deadly Terminator depending on who you ask. But _Machine Learning_ is not just a futuristic fantasy. In fact, it has been around for decades in some specialized applications, such as _Optical Character Recognition (OCR)_. The first ML application that really become main stream took over the world back in the 1990s: it was the _spam filter_. It was followed by hundreds of ML applications that now quietly poweer hundreds of products and features that you use regularly, from better recommendations to voice search.\n",
    "\n",
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning is the science (and art) of _programming computers_ so they can _learn from data_.\n",
    "\n",
    "> [Machine Learning is the] field of study that gives computers the ability to learns without being explicity programmed. --Arthur Samuel, 1959--\n",
    "    \n",
    "> A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. --Tom Mitchell, 1997--\n",
    "\n",
    "The examples that the system uses to learn are called the _training set_. Each training example is called a _training instance_ (or sample). In the case of **spam filter**, the task $T$ is to flag spam from nwe emails, the experience $E$ is the _training data_, and the performance measure $P$ neeeds to be defined; for example, the ratio of correctly classified emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whay use Machine Learning?\n",
    "\n",
    "Consider how you would write a spam filter using traditional programming techinques (Figure 1)\n",
    "\n",
    "<img src=\"./img/fig1.png\" alt=\"traditional approach\" title=\"The traditional approach\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 1**. The traditional approach</center>\n",
    "\n",
    "Since the problem is not trivial, your program will likely become a long list of complex rules.\n",
    "\n",
    "In contrast, a spam filter based on Machine Learning techniques automatically learns which words and phrases are good predictors (Figure  2).\n",
    "\n",
    "<img src=\"./img/fig2.png\" alt=\"Machine Learning\" title=\"Machine Learning approach\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 2**. Machine Learning approach</center>\n",
    "\n",
    "In contrast, a spam filter based on ML automatically notices a change in the words used for spams, and it stats flagging them without intervention (Figure 3).\n",
    "\n",
    "<img src=\"./img/fig3.png\" alt=\"automatically adopting change\" title=\"Automatically adopting change\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 3**. Automatically adopting change</center>\n",
    "\n",
    "Machine Learning can help humans learn (Figure 4): ML algorithms can be inspected to see what they have learned (although for some algorithms this can be tricky). Sometimes this will reveal unsuspected correlations or new trends, and thereby lead to a better understanding of the problem.\n",
    "\n",
    "<img src=\"./img/fig4.png\" alt=\"Machine Learning can help humans learn\" title=\"Machine Learning can help humans learn\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 4**. Machine Learning can help humans learn</center>\n",
    "\n",
    "Applying ML techniques to dig into large amounts of data can help discover patterns that were not immediately apparent. This is called ***data mining.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, ML is great for:\n",
    "\n",
    "* problems for which existing solutions require a lot of hand-tuning or long list of rules: one ML algorithm can often simplyfy code and perform better.\n",
    "* Complex problems for which there is not good solution at all using a traditional approach: the best ML thechique can find a solution.\n",
    "* Fluctuating environments: a ML system can adopt to new data.\n",
    "* Getteing insights about complex problems and large amount of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "Machine Learning system can be classified based on:\n",
    "\n",
    "* Whether or not they are trained with human supervision (supervied, unsupervised, semisupervised, and Reinforcement Learning)\n",
    "* Whether or not they can learn incrementally on the fly (online versus batch learning)\n",
    "* Whether they work by simply comparing new data points to known data points, or insead detect patterns\n",
    "\n",
    "These criteria are not exclusive; you can combine them in any way you like. For example, a state-of-the-art spam filter may learn on the fly using a _deep neural network_ model using examples of spam and ham; thi makes it an online, model-based, supervised learning system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised/Unsupervised learning\n",
    "Machine Learning systems can be classified according to the amount and type of supervision they get during training. There are four major categories: supervised learning, unsipervised learning, semisupervised learning, and Reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised learning\n",
    "In _supervised learning_, the training data you fedd to the algorithm includes the desires soultions, called **labels** (Figure 5). a typical supervised learning task is ***classification***.\n",
    "\n",
    "<img src=\"./img/fig5.png\" alt=\"labeled training\" title=\"A labeled training set for supervised learning (e.g., spam classification)\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 5**. A labeled training set for supervised learning (e.g., spam classification)</center>\n",
    "\n",
    "Another sypical task is to predict a _target_ numeric value, such as the price of a car, given a set of _features_ (mileage, age, brand, etc) called _predictors_. This sort of task is called ***regression*** (Figure 6).\n",
    "\n",
    "<img src=\"./img/fig6.png\" alt=\"regression\" title=\"Regression\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 6**. Regression</center>\n",
    "\n",
    "> In Machine Learning an _attribute__ is a data type (e.g., \"Mileage\"), while a _feature_ has several meanings depending on the context, but generally means an attribute plus its value (e.g., \"Mileage = 15, 000\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised learning\n",
    "In _unsupervised learning_, the training data is unlabeled (Figure 7).\n",
    "\n",
    "<img src=\"./img/fig7.png\" alt=\"unlabeled training\" title=\"An unlabeled training set for unsupervised learning\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 7**. An unlabeled training set for unsupervised learning</center>\n",
    "\n",
    "<img src=\"./img/fig8.png\" alt=\"clustering\" title=\"Clustering\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 8**. Clustering</center>\n",
    "\n",
    "_Visualization_ algorithms are good examples of unsupervised learning algorithms (Figure 9). These algorithms try to preserve as much structure as they can (e.g. trying to keep separate clusters in the input space from overlapping in the visualization), so you can understand how the data id organized and perhaps identify unsuspected patterns.\n",
    "\n",
    "<img src=\"./img/fig9.png\" alt=\"visualization highlighting semantic\" title=\"Example of a t-SNE visualization highlighting semantic clusters\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 9**. Example of a t-SNE visualization highlighting semantic clusters</center>\n",
    "\n",
    "A related task is _dimensionality reduction_, in which the goal is to simplify the data without losing too much information. One way to do this is merge several correlated features into one.\n",
    "\n",
    "Another important unsupervised task is _anomaly detection_. These systems are trained with normal instances, and when it sees a new instance it can tell whether it looks like a normal one or whether it is likely an anormaly (Figure 10).\n",
    "\n",
    "<img src=\"./img/fig10.png\" alt=\"Anomaly detection\" title=\"Anomaly detection\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 10**. Anomaly detection</center>\n",
    "\n",
    "Finally, another common unsupervised task is _association rule learning_, in which the goal is to dig into large amounts of data and discover interesting relations between attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semisupervised learning\n",
    "Some algorithms can deal with partially labeled training data, usually a lot of unlabeled data and a little bit of labeled data. This is called _semisupervised learning_ (Figure 11).\n",
    "\n",
    "<img src=\"./img/fig11.png\" alt=\"semisupervised learning\" title=\"Semisupervised learning\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 11**. Semisupervised learning</center>\n",
    "\n",
    "Most semisupervised learning algorithms are combinations of unsupervised and supervised algorithms. For example, *deep belief networks (DBNs)* are based on unsupervised components called *restricted Boltzmann machines* (RBMs) stacked on top of one another. RBMs are trained sequentially in an unsupervised manner, and then the whole system is fine-tuned using supervised learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement learning\n",
    "*Reinforcement Learning* is a very different beast. The learning system, called an *agent* in this context, can observe the environment, select and perform actions, and get *rewards* in return (or *penalties* in the form of negative rewards, as Figure 12). It must then learn by itself what is the best strategy, called a *policy*, to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation.\n",
    "\n",
    "<img src=\"./img/fig12.png\" alt=\"reinforcement learning\" title=\"Reinforcement Learning\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 12**. Reinforcement Learning</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Online learning\n",
    "Another criterion used to classify Macine Learning systems in whether or nor the system can learn incrementally from a stream of incomming data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch learning\n",
    "In *batch learning*, the system is incapable of learning incrementally: it must be trained using all the available data. First the system is train, and then it is launched into production. This is called *offline learning* (Figure 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online learning\n",
    "In *online learning*, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called *mini-batches*. Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives (Figure 13).\n",
    "\n",
    "<img src=\"./img/fig13.png\" alt=\"online learning\" title=\"Online learning\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 13**. Online learning</center>\n",
    "\n",
    "One an online system has learned about new data instances, it does not need them anymore, so you can discard them. Online learning algorithms can also be used to train systems on huge datasets that cannot fit in one machine's main memory (this is called *out-of*core* learning) The algorithm loads part of the data, runs a training step on that data, and repeats the process until it has run on all of the data (Figure 14.)\n",
    "\n",
    "<img src=\"./img/fig14.png\" alt=\"online learning on huge datasets\" title=\"Using on line learning to handle huge datasets\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 14**. Using on line learning to handle huge datasets</center>\n",
    "\n",
    "One important parameter of online learning systems is how fast they should adapt to changing data: this is called the *learning rate*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance-Based Versus Model learning\n",
    "One more way to categorize Machine Learning systems is by how they *generalize*. Most ML tasks are about making predictions. This means that given a number of training examples, the system needs to be able to generalize to examples it has never seen before. Having a good performance measure on the training data is good, but insufficient; the true goal is to perform well on new instances.\n",
    "\n",
    "There are two main approaches to generalization: instance-based learning and model-based learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance-based learning\n",
    "Possibly the most trivial form of learning is simply to learn by heart. In the email filter example, insted of flagging emails that are identical to known spam emails, your spam filter could be programmed to also flag emails that are very similar to known spam emails. This requires a *measure of similarity*. A (very basic) similarity measure between two emails could be to count the number of words they have in common.\n",
    "\n",
    "This is called *instance-based learning*: the systema learns the example by heart, then generalizes to new cases using a similarity measure (Figure 15).\n",
    "\n",
    "<img src=\"./img/fig15.png\" alt=\"instance-based learning\" title=\"instance-based learning\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 15**. instance-based learning</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model based learning\n",
    "Another way to generalize from a set of examples is to build a model of these examples, these use that model to make *predictions*. This is called *model-based learning* (Figure 16)\n",
    "\n",
    "<img src=\"./img/fig16.png\" alt=\"Model-based learning\" title=\"model-based learning\" width=\"320\" height=\"280\" />\n",
    "<center>**Figure 15**. Model-based learning</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the basic terminology and notations\n",
    "\n",
    "The following table depicts an excerpt of the Iris dataset, which is a classic example in the field of machine learning. The Iris dataset contains the measurements of 150 Iris flowers from three different species—Setosa, Versicolor, and Virginica. Here, each flower sample represents one row in our dataset, and the flower measurements in centimeters are stored as columns, which we also call the features of the dataset:\n",
    "\n",
    "<img src=\"./img/indice.jpeg\" alt=\"data set example\" title=\"dataset example\" width=\"320\" height=\"280\" />\n",
    "<center><strong>Figure 16</strong>. Dataset example for classification.</center>\n",
    "\n",
    "To keep the notation and implementation simple yet efficient, we will make use of some of the basics of linear algebra. We will follow the common convention to represent each sample as a separate row in a feature matrix **X**, where each feature is stored as a separate column.\n",
    "\n",
    "\n",
    "The Iris dataset consisting of 150 samples and four features can then be written as a $150 x 4$ matrix $x \\in \\mathbb{R}^{150x4}$\n",
    "\n",
    "\\begin{bmatrix} \n",
    "x_1 ^{(1)} & x_2^{(1)} & x_3^{(1)} & x_4^{(1)} \\\\\n",
    "x_1 ^{(2)} & x_2^{(2)} & x_3^{(2)} & x_4^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_1 ^{(150)} & x_2^{(150)} & x_3^{(150)} & x_4^{(150)} \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "For example, suppose you want to know if money makes people happy. Download the *bttter Life Index* data from the OECD's website [link](https://goo.gl/0Eht9W \"Better Life Index\") as well as stats about GDP per capita from the IMF's website [link](http://goo.gl/j1MSKe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# to plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"fundamentals\"\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpí=300)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy isse #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = os.path.join(\"datasets\", \"lifesat\", \"\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code example\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "oecd_bli = pd.read_csv(datapath+\"oecd_bli_2015.csv\", thousands=',')\n",
    "gdp_per_capita = pd.read_csv(datapath + \"gdp_per_capita.csv\", thousands=',', delimiter='\\t', encoding='latin1', na_values=\"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza la función de prepare_country_stats y muestra el resultado con head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza los datos mediante una gráfica de disperción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra country_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra los siguientes paises en la grafica de disperción: Japon, Korea, Francia, Australia, Estados Unidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model selection* is the step where you decided which kind of model will use. You selected a *linear model* of life satisfaction with just one attribute, GDP per capita (Equation 1)\n",
    "\n",
    "\\begin{equation*}\n",
    "life\\_satisfaction =\\Theta_0 + \\Theta_1 x GDP\\_per\\_capita\n",
    "\\end{equation*}\n",
    "\n",
    "This model has two *model parameters*, $\\Theta_0$ and $\\Theta_1$. By tweaking these parameters, you can make the model represent any linear function, as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica diferentes rectas (con diferentes pendientes) utilizando la foruma anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can use your model, you need to define the parameter values $\\Theta_0$ and $\\Theta_1$.To do that, you need to specify a performance measure. You can either define a *utility function* (or *fitness function*) that measures how good your model is, or you can define a *cost function* that measures how bad.\n",
    "\n",
    "For linear regression problems, people tipically use a cost function that measures the distance between the linear model's predictions and the training examples; the objective is to **minimize the distance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un modelo utilizando sklearn.linear_model.LinearRegression().\n",
    "# Además de mostrar los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica la recta obtenida de los coeficientes anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are finally ready to run the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza una predicción para \"Cyprus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza una predicción para \"México\". ¿Es correcta la estimación de la \"felicidad\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra con una gráfica, la predicción en la recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In summary\n",
    " * You studied the data\n",
    " * You selected a model\n",
    " * You trained it on the training data (i.e. the learning algorithm searched for the model parameter values that minimize a cost function).\n",
    " * Finally, you applied the model to make predictions on new cases (this is called *inference*), hoping that this model will generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
